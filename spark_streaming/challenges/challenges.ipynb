{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lucprosa/dataeng-basic-course/blob/main/spark_streaming/challenges/challenges.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_GBE9UsyxwK"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9LeYFsPTjAb"
      },
      "source": [
        "# Setting up PySpark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uYXeODL0T1fO",
        "outputId": "b805aca4-2d12-47de-d985-2b8a22eeb565"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.5.3)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "%pip install pyspark"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rcybt71kTDNt"
      },
      "source": [
        "# Context\n",
        "Message events are coming from platform message broker (kafka, pubsub, kinesis...).\n",
        "You need to process the data according to the requirements.\n",
        "\n",
        "Message schema:\n",
        "- timestamp\n",
        "- value\n",
        "- event_type\n",
        "- message_id\n",
        "- country_id\n",
        "- user_id\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Challenge 1\n",
        "\n",
        "Step 1\n",
        "- Change exising producer\n",
        "\t- Change parquet location to \"/content/lake/bronze/messages/data\"\n",
        "\t- Add checkpoint (/content/lake/bronze/messages/checkpoint)\n",
        "\t- Delete /content/lake/bronze/messages and reprocess data\n",
        "\t- For reprocessing, run the streaming for at least 1 minute, then stop it\n",
        "\n",
        "Step 2\n",
        "- Implement new stream job to read from messages in bronze layer and split result in to locations\n",
        "\t- \"messages_corrupted\"\n",
        "\t\t- logic: event_status is null, empty or equal to \"NONE\"\n",
        "    - extra logic: add country name by joining message with countries dataset\n",
        "\t\t- partition by \"date\" -extract it from timestamp\n",
        "\t\t- location: /content/lake/silver/messages_corrupted/data\n",
        "\n",
        "\t- \"messages\"\n",
        "\t\t- logic: not corrupted data\n",
        "\t\t- extra logic: add country name by joining message with countries dataset\n",
        "\t\t- partition by \"date\" -extract it from timestamp\n",
        "\t\t- location: /content/lake/silver/messages/data\n",
        "\n",
        "\t- technical requirements\n",
        "\t\t- add checkpint (choose location)\n",
        "\t\t- use StructSchema\n",
        "\t\t- Set trigger interval to 5 seconds\n",
        "\t\t- run streaming for at least 20 seconds, then stop it\n",
        "\n",
        "\t- alternatives\n",
        "\t\t- implementing single streaming job with foreach/- foreachBatch logic to write into two locations\n",
        "\t\t- implementing two streaming jobs, one for messages and another for messages_corrupted\n",
        "\t\t- (paying attention on the paths and checkpoints)\n",
        "\n",
        "\n",
        "  - Check results:\n",
        "    - results from messages in bronze layer should match with the sum of messages+messages_corrupted in the silver layer"
      ],
      "metadata": {
        "id": "JkyPORKNSYvV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Udk3tohSaXOH",
        "outputId": "de9b696a-aceb-42c6-ff45-1bab77511796"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: faker in /usr/local/lib/python3.10/dist-packages (33.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.4 in /usr/local/lib/python3.10/dist-packages (from faker) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from faker) (4.12.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.4->faker) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "%pip install faker"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {
        "id": "aFdP7uDQdbWp"
      },
      "outputs": [],
      "source": [
        "!rm -rf content/lake"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDGMKwBdi1qy"
      },
      "source": [
        "# Producer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tPCOdivrfhYh",
        "outputId": "d64c5b30-ab8c-4fdb-e5bf-7eeeea967874"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 148
        }
      ],
      "source": [
        "import pyspark.sql.functions as F\n",
        "from pyspark.sql import DataFrame\n",
        "from faker import Faker\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder.appName('Test streaming').getOrCreate()\n",
        "sc = spark.sparkContext\n",
        "\n",
        "fake = Faker()\n",
        "messages = [fake.uuid4() for _ in range(50)]\n",
        "\n",
        "def enrich_data(df, messages=messages):\n",
        "  fake = Faker()\n",
        "  new_columns = {\n",
        "      'event_type': F.lit(fake.random_element(elements=('OPEN', 'RECEIVED', 'SENT', 'CREATED', 'CLICKED', '', 'NONE'))),\n",
        "      'message_id': F.lit(fake.random_element(elements=messages)),\n",
        "      'channel': F.lit(fake.random_element(elements=('CHAT', 'EMAIL', 'SMS', 'PUSH', 'OTHER'))),\n",
        "      'country_id': F.lit(fake.random_int(min=2000, max=2015)),\n",
        "      'user_id': F.lit(fake.random_int(min=1000, max=1050)),\n",
        "  }\n",
        "  df = df.withColumns(new_columns)\n",
        "  return df\n",
        "\n",
        "def insert_messages(df: DataFrame, batch_id):\n",
        "  enrich = enrich_data(df)\n",
        "  enrich.write.mode(\"append\").format(\"parquet\").save(\"content/lake/bronze/messages\")\n",
        "\n",
        "# read stream\n",
        "df_stream = spark.readStream.format(\"rate\").option(\"rowsPerSecond\", 1).load()\n",
        "\n",
        "# write stream\n",
        "query = (df_stream.writeStream\n",
        ".outputMode('append')\n",
        ".trigger(processingTime='1 seconds')\n",
        ".foreachBatch(insert_messages)\n",
        ".start()\n",
        ")\n",
        "\n",
        "query.awaitTermination(60)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "metadata": {
        "id": "KNyUK3yplDhg"
      },
      "outputs": [],
      "source": [
        "query.stop()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZWQExsnzlMFe",
        "outputId": "93810d79-e674-442f-9890-5d12de3714bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-----+----------+--------------------+-------+----------+-------+\n",
            "|           timestamp|value|event_type|          message_id|channel|country_id|user_id|\n",
            "+--------------------+-----+----------+--------------------+-------+----------+-------+\n",
            "|2024-12-03 21:01:...|  135|  RECEIVED|3de01bc0-78f4-401...|  EMAIL|      2000|   1025|\n",
            "|2024-12-03 21:00:...|  114|  RECEIVED|5be8f6f1-dedd-4fe...|  EMAIL|      2003|   1033|\n",
            "|2024-12-03 21:00:...|  119|  RECEIVED|bf899e5d-582e-4b0...|  EMAIL|      2006|   1000|\n",
            "|2024-12-03 20:59:...|   72|  RECEIVED|cd29b0fc-4416-428...|  EMAIL|      2013|   1035|\n",
            "|2024-12-03 21:00:...|   78|  RECEIVED|a6bd0277-f664-483...|  OTHER|      2012|   1013|\n",
            "|2024-12-03 21:00:...|  131|  RECEIVED|dfe8f040-1f4a-42f...|  OTHER|      2006|   1008|\n",
            "|2024-12-03 21:00:...|   86|  RECEIVED|ce1960f4-db7f-4e8...|  OTHER|      2000|   1024|\n",
            "|2024-12-03 20:59:...|   62|  RECEIVED|77f57a48-d7af-436...|  OTHER|      2005|   1026|\n",
            "|2024-12-03 20:59:...|   32|   CREATED|26ac381d-aecc-4e1...|  EMAIL|      2002|   1048|\n",
            "|2024-12-03 21:00:...|  132|  RECEIVED|5845fa6c-ded6-416...|   CHAT|      2006|   1014|\n",
            "|2024-12-03 21:00:...|  129|   CLICKED|fe7d3c63-a3e7-4a6...|  EMAIL|      2014|   1050|\n",
            "|2024-12-03 21:00:...|  124|  RECEIVED|b1836ceb-22d2-4fe...|   CHAT|      2001|   1031|\n",
            "|2024-12-03 20:58:...|    7|   CREATED|538c4e48-2c45-49a...|  EMAIL|      2000|   1043|\n",
            "|2024-12-03 21:00:...|   83|   CLICKED|fc238500-ac50-449...|  EMAIL|      2008|   1003|\n",
            "|2024-12-03 20:58:...|   12|  RECEIVED|47c87abd-04c3-40a...|   CHAT|      2013|   1004|\n",
            "|2024-12-03 21:00:...|   84|  RECEIVED|79bc9ee4-6bd5-463...|   CHAT|      2006|   1034|\n",
            "|2024-12-03 20:59:...|   34|   CREATED|581ab2d3-81c4-4c1...|  EMAIL|      2008|   1039|\n",
            "|2024-12-03 20:59:...|   55|  RECEIVED|81588b76-6b32-460...|   PUSH|      2000|   1047|\n",
            "|2024-12-03 21:00:...|  128|   CLICKED|11c9806e-7a6f-462...|  EMAIL|      2014|   1047|\n",
            "|2024-12-03 20:59:...|   60|  RECEIVED|fc238500-ac50-449...|   CHAT|      2002|   1042|\n",
            "+--------------------+-----+----------+--------------------+-------+----------+-------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df = spark.read.format(\"parquet\").load(\"content/lake/bronze/messages/*\")\n",
        "df.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Additional datasets"
      ],
      "metadata": {
        "id": "RraxHCycMdEZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "countries = [\n",
        "    {\"country_id\": 2000, \"country\": \"Brazil\"},\n",
        "    {\"country_id\": 2001, \"country\": \"Portugal\"},\n",
        "    {\"country_id\": 2002, \"country\": \"Spain\"},\n",
        "    {\"country_id\": 2003, \"country\": \"Germany\"},\n",
        "    {\"country_id\": 2004, \"country\": \"France\"},\n",
        "    {\"country_id\": 2005, \"country\": \"Italy\"},\n",
        "    {\"country_id\": 2006, \"country\": \"United Kingdom\"},\n",
        "    {\"country_id\": 2007, \"country\": \"United States\"},\n",
        "    {\"country_id\": 2008, \"country\": \"Canada\"},\n",
        "    {\"country_id\": 2009, \"country\": \"Australia\"},\n",
        "    {\"country_id\": 2010, \"country\": \"Japan\"},\n",
        "    {\"country_id\": 2011, \"country\": \"China\"},\n",
        "    {\"country_id\": 2012, \"country\": \"India\"},\n",
        "    {\"country_id\": 2013, \"country\": \"South Korea\"},\n",
        "    {\"country_id\": 2014, \"country\": \"Russia\"},\n",
        "    {\"country_id\": 2015, \"country\": \"Argentina\"}\n",
        "]\n",
        "\n",
        "countries = spark.createDataFrame(countries)"
      ],
      "metadata": {
        "id": "cfsus3dxMcQI"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Pg2nx03_Sn62"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swvPj9hVpzNf"
      },
      "source": [
        "# Streaming Messages Corrupted"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf content/lake/silver/"
      ],
      "metadata": {
        "id": "L31Dxyw_Qqj8"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZAHIZeZMlpoH",
        "outputId": "112472fb-eda9-4fb0-e7f4-365f08940886"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 151
        }
      ],
      "source": [
        "from pyspark.sql.types import *\n",
        "\n",
        "def insert_messages_silver(df: DataFrame, batch_id):\n",
        "  corrupted = df.filter(F.col('event_type').isin('NONE', '') | F.col('event_type').isNull())\n",
        "  messages = df.exceptAll(corrupted)\n",
        "\n",
        "  if corrupted.count() > 0:\n",
        "    corrupted.write.mode(\"append\").partitionBy(\"date\").format(\"parquet\").save(\"content/lake/silver/messages_corrupted\")\n",
        "  if messages.count() > 0:\n",
        "    messages.write.mode(\"append\").partitionBy(\"date\").format(\"parquet\").save(\"content/lake/silver/messages\")\n",
        "\n",
        "schema = StructType([StructField('timestamp', TimestampType(), True), StructField('value', LongType(), True), StructField('event_type', StringType(), True), StructField('message_id', StringType(), True), StructField('channel', StringType(), True), StructField('country_id', IntegerType(), True), StructField('user_id', IntegerType(), True), StructField('date', DateType(), True)])\n",
        "# read stream\n",
        "df_stream = spark.readStream.format(\"parquet\").schema(schema).load(\"content/lake/bronze/messages/*\")\n",
        "\n",
        "df_transformed = df_stream.withColumn(\"date\", F.to_date(F.col(\"timestamp\")))\n",
        "\n",
        "df_joined = df_transformed.join(F.broadcast(countries), [\"country_id\"], \"left\")\n",
        "\n",
        "# write stream\n",
        "query = (df_joined.writeStream\n",
        ".outputMode('append')\n",
        ".trigger(processingTime='5 seconds')\n",
        ".foreachBatch(insert_messages_silver)\n",
        ".start()\n",
        ")\n",
        "\n",
        "query.awaitTermination(20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {
        "id": "TinO47Q6molI"
      },
      "outputs": [],
      "source": [
        "query.stop()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nk8seEvbmvcU",
        "outputId": "36936892-2e13-4712-c7df-849835b875d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "142\n",
            "102\n",
            "40\n"
          ]
        }
      ],
      "source": [
        "print(spark.read.format(\"parquet\").load(\"content/lake/bronze/messages\").count())\n",
        "print(spark.read.format(\"parquet\").load(\"content/lake/silver/messages\").count())\n",
        "print(spark.read.format(\"parquet\").load(\"content/lake/silver/messages_corrupted\").count())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#"
      ],
      "metadata": {
        "id": "sLOYzIRoR1Br"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Challenge 2\n",
        "\n",
        "- Run business report\n",
        "- But first, there is a bug in the system which is causing some duplicated messages, we need to exclude these lines from the report\n",
        "\n",
        "- Technical requirements:\n",
        "  - Identify possible duplicates on message_id, event_type and channel\n",
        "  - in case of duplicates, consider only the first message (occurrence by timestamp)\n",
        "  - Ex:\n",
        "    In table below, the correct message to consider is the second line\n",
        "\n",
        "```\n",
        "    message_id | channel | event_type | timestamp\n",
        "    123        | CHAT    | CREATED    | 10:10:01\n",
        "    123        | CHAT    | CREATED    | 07:56:45 (first occurrence)\n",
        "    123        | CHAT    | CREATED    | 08:13:33\n",
        "```\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "rfxIlBISSvRP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.read.format(\"parquet\").load(\"content/lake/silver/messages\")\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UPHSMSXnTKgu",
        "outputId": "105b6060-4260-4717-ad60-f815c1f8b549"
      },
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+--------------------+-----+----------+--------------------+-------+-------+--------------+----------+\n",
            "|country_id|           timestamp|value|event_type|          message_id|channel|user_id|       country|      date|\n",
            "+----------+--------------------+-----+----------+--------------------+-------+-------+--------------+----------+\n",
            "|      2006|2024-12-03 21:00:...|  119|  RECEIVED|bf899e5d-582e-4b0...|  EMAIL|   1000|United Kingdom|2024-12-03|\n",
            "|      2006|2024-12-03 21:00:...|  131|  RECEIVED|dfe8f040-1f4a-42f...|  OTHER|   1008|United Kingdom|2024-12-03|\n",
            "|      2006|2024-12-03 20:59:...|   28|   CREATED|77ee9a01-90c7-48c...|  EMAIL|   1027|United Kingdom|2024-12-03|\n",
            "|      2006|2024-12-03 21:00:...|  132|  RECEIVED|5845fa6c-ded6-416...|   CHAT|   1014|United Kingdom|2024-12-03|\n",
            "|      2007|2024-12-03 21:00:...|  109|   CREATED|58f825b3-7ed2-4d0...|  OTHER|   1022| United States|2024-12-03|\n",
            "|      2007|2024-12-03 20:59:...|   66|   CREATED|79bc9ee4-6bd5-463...|   PUSH|   1004| United States|2024-12-03|\n",
            "|      2006|2024-12-03 20:59:...|   33|   CREATED|9b12f354-ddcf-4d0...|    SMS|   1049|United Kingdom|2024-12-03|\n",
            "|      2007|2024-12-03 21:00:...|   85|   CLICKED|25da12ba-26cb-43d...|    SMS|   1013| United States|2024-12-03|\n",
            "|      2013|2024-12-03 20:59:...|   16|   CREATED|538c4e48-2c45-49a...|   PUSH|   1046|   South Korea|2024-12-03|\n",
            "|      2013|2024-12-03 21:00:...|  116|   CREATED|dfe8f040-1f4a-42f...|   CHAT|   1020|   South Korea|2024-12-03|\n",
            "|      2013|2024-12-03 20:59:...|   35|   CLICKED|8db02aec-7994-432...|   CHAT|   1024|   South Korea|2024-12-03|\n",
            "|      2013|2024-12-03 20:59:...|   21|   CREATED|cd29b0fc-4416-428...|   PUSH|   1050|   South Korea|2024-12-03|\n",
            "|      2015|2024-12-03 21:00:...|   80|   CREATED|d166620f-0cc0-4ae...|  OTHER|   1027|     Argentina|2024-12-03|\n",
            "|      2015|2024-12-03 20:59:...|   39|   CLICKED|11c9806e-7a6f-462...|  EMAIL|   1048|     Argentina|2024-12-03|\n",
            "|      2009|2024-12-03 21:00:...|  118|   CLICKED|bf899e5d-582e-4b0...|  OTHER|   1043|     Australia|2024-12-03|\n",
            "|      2007|2024-12-03 20:59:...|   18|      OPEN|dce1b5c9-f449-4d1...|   PUSH|   1047| United States|2024-12-03|\n",
            "|      2007|2024-12-03 20:59:...|   13|      SENT|6e8e40ff-edfe-4dc...|   PUSH|   1015| United States|2024-12-03|\n",
            "|      2014|2024-12-03 21:00:...|  104|   CLICKED|bc1ef7ea-459b-4f7...|  OTHER|   1044|        Russia|2024-12-03|\n",
            "|      2005|2024-12-03 20:59:...|   20|   CLICKED|9d872ba7-fb67-424...|    SMS|   1017|         Italy|2024-12-03|\n",
            "|      2002|2024-12-03 21:00:...|   97|      SENT|ea96258f-0321-42d...|  EMAIL|   1023|         Spain|2024-12-03|\n",
            "+----------+--------------------+-----+----------+--------------------+-------+-------+--------------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.select(\"message_id\").distinct().count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V1BZ7X3CUGNG",
        "outputId": "a35fd1d6-8aeb-4d0b-8678-bd5cc05192b7"
      },
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "46"
            ]
          },
          "metadata": {},
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MXbLgH6NTd0H",
        "outputId": "09609edd-90c9-45b2-f140-926e52b01f78"
      },
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "102"
            ]
          },
          "metadata": {},
          "execution_count": 156
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "metadata": {
        "id": "7fy2f1j9nWBk"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import functions as F\n",
        "from pyspark.sql.window import Window\n",
        "df2 = df.withColumn(\"row_number\", F.row_number().over(Window.partitionBy(\"message_id\", \"event_type\", \"channel\").orderBy(\"timestamp\"))).filter(\"row_number = 1\").drop(\"row_number\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df2.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iinn-KKTTe8i",
        "outputId": "8ddd9e5b-769e-490b-be5d-1c14809229ce"
      },
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "98"
            ]
          },
          "metadata": {},
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YByUNvPUTjrv"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
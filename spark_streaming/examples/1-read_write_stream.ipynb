{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/lucprosa/dataeng-basic-course/blob/main/spark_streaming/examples/1-read_write_stream.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4_GBE9UsyxwK"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BOA_wQSmLd9z"
   },
   "source": [
    "# Usecase 2\n",
    "- Reading data from \"rate\"\n",
    "- Aggregating data by window time\n",
    "- Checking results from query in memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d9LeYFsPTjAb"
   },
   "source": [
    "# Setting up PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uYXeODL0T1fO",
    "outputId": "c410e46c-4a50-43aa-926f-d0417c6280d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.5.3)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n"
     ]
    }
   ],
   "source": [
    "%pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "637HFw00T3LP"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.master('local').appName('Test streaming').config('spark.ui.port', '4050').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I4mGPfB-Xg_C"
   },
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "\n",
    "# read stream\n",
    "stream1 = spark.readStream.format(\"rate\").option(\"rowsPerSecond\", 10).load()\n",
    "\n",
    "# transform\n",
    "transformed = stream1.withColumn(\"minute\", F.minute(\"timestamp\"))\n",
    "agg = transformed.groupBy(F.window(transformed.timestamp, \"5 seconds\")).count()\n",
    "\n",
    "# write stream\n",
    "query = (agg.writeStream\n",
    ".format('memory')\n",
    ".queryName('my_query')\n",
    ".outputMode('complete')\n",
    ".start()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UmLQLr1uX6w-",
    "outputId": "d3c1e349-b5c2-4b95-8db4-cc02cbf6743b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------+-----+\n",
      "|window                                    |count|\n",
      "+------------------------------------------+-----+\n",
      "|{2024-11-05 18:12:25, 2024-11-05 18:12:30}|29   |\n",
      "|{2024-11-05 18:12:20, 2024-11-05 18:12:25}|50   |\n",
      "|{2024-11-05 18:12:15, 2024-11-05 18:12:20}|50   |\n",
      "|{2024-11-05 18:12:10, 2024-11-05 18:12:15}|50   |\n",
      "|{2024-11-05 18:12:05, 2024-11-05 18:12:10}|50   |\n",
      "|{2024-11-05 18:12:00, 2024-11-05 18:12:05}|50   |\n",
      "|{2024-11-05 18:11:55, 2024-11-05 18:12:00}|50   |\n",
      "|{2024-11-05 18:11:50, 2024-11-05 18:11:55}|50   |\n",
      "|{2024-11-05 18:11:45, 2024-11-05 18:11:50}|50   |\n",
      "|{2024-11-05 18:11:40, 2024-11-05 18:11:45}|50   |\n",
      "+------------------------------------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from my_query order by window desc\").show(10,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TbLt4cUkX-JZ"
   },
   "outputs": [],
   "source": [
    "query.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v180mzIciVZH"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Tasks:\n",
    "## Create/extract column \"minute\" from the timestamp\n",
    "## Save output as JSON without partitioning / or partitioned by minute\n",
    "\n",
    "# Questions:\n",
    "##\n",
    "##\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_gauZX8MFP5f",
    "outputId": "c81555fb-fc5d-409f-e6a2-b4bae1388503"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting faker\n",
      "  Downloading Faker-33.0.0-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.4 in /usr/local/lib/python3.10/dist-packages (from faker) (2.8.2)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from faker) (4.12.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.4->faker) (1.16.0)\n",
      "Downloading Faker-33.0.0-py3-none-any.whl (1.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: faker\n",
      "Successfully installed faker-33.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install faker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 216
    },
    "id": "WCUhAzDOD4Q3",
    "outputId": "c4498723-1db1-4230-e888-3efb7454ee85"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataStreamReader' object has no attribute 'transform'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-761118126a5e>\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mreadStream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"rate\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0moption\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"rowsPerSecond\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menrich_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataStreamReader' object has no attribute 'transform'"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import DataFrame\n",
    "from faker import Faker\n",
    "\n",
    "def enrich_df(df: DataFrame) -> DataFrame:\n",
    "  fake = Faker()\n",
    "  new_columns = {\n",
    "      'name': F.lit(fake.name()),\n",
    "      'address': F.lit(fake.address()),\n",
    "      'email': F.lit(fake.email()),\n",
    "      'dob': F.lit(fake.date_of_birth()),\n",
    "      'phone': F.lit(fake.phone_number())\n",
    "  }\n",
    "  df = df.withColumns(new_columns)\n",
    "  return df\n",
    "\n",
    "# read stream\n",
    "df_stream = spark.readStream.format(\"rate\").option(\"rowsPerSecond\", 10).load()\n",
    "\n",
    "# write stream\n",
    "query = (df_stream.writeStream\n",
    ".format('memory')\n",
    ".queryName('enriched')\n",
    ".outputMode('append')\n",
    ".start()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "W4bsXBZ6EPW_"
   },
   "outputs": [],
   "source": [
    "query.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "89s50dHjECqk",
    "outputId": "07561df0-e789-41fc-85c6-e37fa9d55aa7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+----------+--------------------+--------------------+----------+------------+\n",
      "|           timestamp|value|      name|             address|               email|       dob|       phone|\n",
      "+--------------------+-----+----------+--------------------+--------------------+----------+------------+\n",
      "|2024-11-19 20:32:...|    0|John Silva|21383 Davis Green...|isabelsalas@examp...|1942-01-04|775.239.3916|\n",
      "|2024-11-19 20:32:...|    1|John Silva|21383 Davis Green...|isabelsalas@examp...|1942-01-04|775.239.3916|\n",
      "|2024-11-19 20:32:...|    2|John Silva|21383 Davis Green...|isabelsalas@examp...|1942-01-04|775.239.3916|\n",
      "|2024-11-19 20:32:...|    3|John Silva|21383 Davis Green...|isabelsalas@examp...|1942-01-04|775.239.3916|\n",
      "|2024-11-19 20:32:...|    4|John Silva|21383 Davis Green...|isabelsalas@examp...|1942-01-04|775.239.3916|\n",
      "|2024-11-19 20:32:...|    5|John Silva|21383 Davis Green...|isabelsalas@examp...|1942-01-04|775.239.3916|\n",
      "|2024-11-19 20:32:...|    6|John Silva|21383 Davis Green...|isabelsalas@examp...|1942-01-04|775.239.3916|\n",
      "|2024-11-19 20:32:...|    7|John Silva|21383 Davis Green...|isabelsalas@examp...|1942-01-04|775.239.3916|\n",
      "|2024-11-19 20:32:...|    8|John Silva|21383 Davis Green...|isabelsalas@examp...|1942-01-04|775.239.3916|\n",
      "|2024-11-19 20:32:...|    9|John Silva|21383 Davis Green...|isabelsalas@examp...|1942-01-04|775.239.3916|\n",
      "|2024-11-19 20:32:...|   10|John Silva|21383 Davis Green...|isabelsalas@examp...|1942-01-04|775.239.3916|\n",
      "|2024-11-19 20:32:...|   11|John Silva|21383 Davis Green...|isabelsalas@examp...|1942-01-04|775.239.3916|\n",
      "|2024-11-19 20:32:...|   12|John Silva|21383 Davis Green...|isabelsalas@examp...|1942-01-04|775.239.3916|\n",
      "|2024-11-19 20:32:...|   13|John Silva|21383 Davis Green...|isabelsalas@examp...|1942-01-04|775.239.3916|\n",
      "|2024-11-19 20:32:...|   14|John Silva|21383 Davis Green...|isabelsalas@examp...|1942-01-04|775.239.3916|\n",
      "|2024-11-19 20:32:...|   15|John Silva|21383 Davis Green...|isabelsalas@examp...|1942-01-04|775.239.3916|\n",
      "|2024-11-19 20:32:...|   16|John Silva|21383 Davis Green...|isabelsalas@examp...|1942-01-04|775.239.3916|\n",
      "|2024-11-19 20:32:...|   17|John Silva|21383 Davis Green...|isabelsalas@examp...|1942-01-04|775.239.3916|\n",
      "|2024-11-19 20:32:...|   18|John Silva|21383 Davis Green...|isabelsalas@examp...|1942-01-04|775.239.3916|\n",
      "|2024-11-19 20:32:...|   19|John Silva|21383 Davis Green...|isabelsalas@examp...|1942-01-04|775.239.3916|\n",
      "+--------------------+-----+----------+--------------------+--------------------+----------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from enriched\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "m22vpxcxIUNa"
   },
   "outputs": [],
   "source": [
    "query.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KhoudBI7EG0o"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
